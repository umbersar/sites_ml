source('C:/Users/horat/Desktop/CSIRO Intership/CODEDEMO/naiveBaiyes.r', echo=TRUE)
source('C:/Users/horat/Desktop/CSIRO Intership/CODEDEMO/naiveBaiyes.r', echo=TRUE)
source('C:/Users/horat/Desktop/CSIRO Intership/CODEDEMO/naiveBaiyes.r', echo=TRUE)
source('C:/Users/horat/Desktop/CSIRO Intership/CODEDEMO/naiveBaiyes.r', echo=TRUE)
library(ggplot2) # Data visualization
library(plotly) # Interactive data visualizations
library(psych) # Will be used for correlation visualizations
library(rattle) # Graphing decision trees
library(caret) # Machine learning
data("iris")
set.seed(222)
train_index <- createDataPartition(y = iris$Species,
p = .7,
list = FALSE,
times = 1)
train_data <- iris[train_index]
test_data <- iris[-train_index]
fit_Control <- trainControl(method = "cv",number= 10,savePredictions = TRUE)
# Create model
nb_model <- train(Species ~ ., # Set y variable followed by '~'. The period indicates that we want to use all our variables for prediction.
data = train_data,
method = 'nb', # Specify Naive Bayes model
trControl = fit_Control) # Use cross validation
confusionMatrix(nb_model)
source('C:/Users/horat/Desktop/CSIRO Intership/CODEDEMO/naiveBaiyes.r', echo=TRUE)
help(train)
# Create model
nb_model <- train(Species ~ ., # Set y variable followed by '~'. The period indicates that we want to use all our variables for prediction.
method = 'nb', # Specify Naive Bayes model
trControl = fit_Control,
data = train_data,) # Use cross validation
source('C:/Users/horat/Desktop/CSIRO Intership/CODEDEMO/naiveBaiyes.r', echo=TRUE)
test_data <- iris[-train_index]
fit_Control <- trainControl(method = "cv",number= 10,savePredictions = TRUE)
# Create model
nb_model <- train(Species ~ ., # Set y variable followed by '~'. The period indicates that we want to use all our variables for prediction.
method = 'nb', # Specify Naive Bayes model
trControl = fit_Control,
data = train_data,) # Use cross validation
confusionMatrix(nb_model)
train_index <- createDataPartition(y = iris$Species,
p = .7,
list = FALSE,
times = 1)
train_data <- iris[train_index]
test_data <- iris[-train_index]
fit_Control <- trainControl(method = "cv",number= 10,savePredictions = TRUE)
# Create model
nb_model <- train(Species ~ ., # Set y variable followed by '~'. The period indicates that we want to use all our variables for prediction.
method = 'nb', # Specify Naive Bayes model
trControl = fit_Control,
data = train_data,) # Use cross validation
confusionMatrix(nb_model)
train_data
test_data <- iris[-train_index,]
fit_Control <- trainControl(method = "cv",number= 10,savePredictions = TRUE)
# Create model
nb_model <- train(Species ~ ., # Set y variable followed by '~'. The period indicates that we want to use all our variables for prediction.
method = 'nb', # Specify Naive Bayes model
trControl = fit_Control,
data = train_data,) # Use cross validation
set.seed(222)
train_index <- createDataPartition(y = iris$Species,
p = .7,
list = FALSE,
times = 1)
train_data <- iris[train_index,]
train_data
library(plotly) # Interactive data visualizations
library(psych) # Will be used for correlation visualizations
library(rattle) # Graphing decision trees
library(caret) # Machine learning
data("iris")
set.seed(222)
train_index <- createDataPartition(y = iris$Species,
p = .7,
list = FALSE,
times = 1)
train_data <- iris[train_index,]
test_data <- iris[-train_index,]
fit_Control <- trainControl(method = "cv",number= 10,savePredictions = TRUE)
# Create model
nb_model <- train(Species ~ ., # Set y variable followed by '~'. The period indicates that we want to use all our variables for prediction.
method = 'nb', # Specify Naive Bayes model
trControl = fit_Control,
data = train_data,) # Use cross validation
confusionMatrix(nb_model)
nb_importance <- varImp(nb_model)
nb_importance[,1]
source('C:/Users/horat/Desktop/CSIRO Intership/CODEDEMO/naiveBaiyes.r', echo=TRUE)
prediction_nb <- predict(nb_model)
test_data$Species
prediction_nb
table(prediction_nb,test_data$Species)
source('C:/Users/horat/Desktop/CSIRO Intership/CODEDEMO/naiveBaiyes.r', echo=TRUE)
# Create model
nb_model <- train(Species ~ ., # Set y variable followed by '~'. The period indicates that we want to use all our variables for prediction.
method = 'nb', # Specify Naive Bayes model
trControl = fit_Control,
data = train_data,) # Use cross validation
confusionMatrix(nb_model)
prediction_nb
prediction_nb
prediction_nb <- predict(nb_model,test_model)
source('C:/Users/horat/Desktop/CSIRO Intership/CODEDEMO/naiveBaiyes.r', echo=TRUE)
source('C:/Users/horat/Desktop/CSIRO Intership/CODEDEMO/naiveBaiyes.r', echo=TRUE)
source('C:/Users/horat/Desktop/CSIRO Intership/CODEDEMO/naiveBaiyes.r', echo=TRUE)
table(prediction_svm, test_data$Species) %>% # Create prediction table.
prop.table() %>% # Convert table values into proportions instead of counts.
round(2) # Round numbers to 2 significant values.
source('C:/Users/horat/Desktop/CSIRO Intership/CODEDEMO/svm.r', echo=TRUE)
svm_model <- train(Species ~ .,
data = train_data,
method = 'svmLinear',
trControl = fit_Control)
source('C:/Users/horat/Desktop/CSIRO Intership/CODEDEMO/svm.r', echo=TRUE)
install.packages("fastAdaboost")
library(fastAdaboost)
a <- 1
b <- 1:10
library (psych)
library (plotly)
library (ggplot2)
library (rattle)
library (caret)
data("iris")
set.seed(22)
train_index<- createDataPartition(
y = iris$Species,
p = 0.7,
list = FALSE,
times = 1
)
train_data <- iris[train_index,]
test_data <- iris[-train_index,]
fitControl <- trainControl(method = "cv",number = 10,savePredictions = TRUE)
# Create model
dt_model <- train(Species ~ ., # Set Y variable followed by '~'. The period indicates to include all variables for prediction.
data = train_data, # Data
method = 'rpart', # Specify SVM model
trControl = fitControl) # Use cross validation
value <- confusionMatrix(dt_model)
dt_importance <- varImp(dt_model)
# Create plot of importance of variables
ggplot(data = dt_importance, mapping = aes(x = dt_importance[,1])) + # Data & mapping
geom_boxplot() + # Create box plot
labs(title = "Variable importance: Decision tree model") + # Title
theme_light() # Theme
#plot it
fancyRpartPlot(dt_model$finalModel,sub = "")
predict_dt <- predict(dt_model,test_data)
prop.table(table(predict_dt, test_data$Species)) %>%
round(2)
install.packages(ipred)
install.packages("ipred")
install.packages("ipred")
install.packages("ipred")
install.packages("ipred")
install.packages("ipred")
library(ipred)
library(caret)
data(iris)
set.seed(222)
index <- createDataPartition(iris$Species,p=0.7,list = F)
train_data <- iris[index,]
test_data <- iris[index,]
fit_Control <- trainControl(method = "cv",number = 10,savePredictions = True)
cpGrid = expand.grid(.cp=seq(0.0005,0.05,0.0005))
cart <- train(Species ~ .,
data = train_data,
method = "rpart",
trControl = fit_Control,
tuneGrid = cpGrid)
source('C:/Users/horat/Desktop/CSIROIntership/CODEDEMO/cart.r', echo=TRUE)
View(cart)
source('C:/Users/horat/Desktop/CSIROIntership/CODEDEMO/cart.r', echo=TRUE)
source('C:/Users/horat/Desktop/CSIROIntership/CODEDEMO/cart.r', echo=TRUE)
source('C:/Users/horat/Desktop/CSIROIntership/CODEDEMO/cart.r', echo=TRUE)
test_data <- iris[-index,]
source('C:/Users/horat/Desktop/CSIROIntership/CODEDEMO/cart.r', echo=TRUE)
source('C:/Users/horat/Desktop/CSIROIntership/CODEDEMO/cart.r', echo=TRUE)
install.packages(xgpboost)
install.packages('xgpboost')
install.packages('xgboost')
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
train_data
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
train_data
library(xgboost)
library(caret)
data(iris)
index <- createDataPartition(iris$Species, p =0.7, list =F)
train_data <- iris[index,]
test_data <- iris[-index,]
train_data$Species <-  factor(train_data$Species)
train_data
train_data$Species
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
help(xgb)
help(DMatrix)
library(xgboost)
help(DMatrix)
help(??trix)
help("DMatrix")
source('~/.active-rstudio-document', echo=TRUE)
test_data <- data.frame(iris[-index,])
#transform teh two data sets into xgb.Matrix
xgb.train = xgb.DMatrix(data = train_data,label = train_data$Species)
source('~/.active-rstudio-document', echo=TRUE)
library(xgboost)
library(caret)
data(iris)
iris$Species <-  factor(iris$Species)
index <- createDataPartition(iris$Species, p =0.7, list =F)
train_data <- as.matrix(iris[index,])
test_data <- as.matrix(iris[-index,])
#transform teh two data sets into xgb.Matrix
xgb.train = xgb.DMatrix(data = train_data,label = as.matrix(train_data$Species))
library(xgboost)
library(caret)
data(iris)
index <- createDataPartition(iris$Species, p =0.7, list =F)
train_data <- iris[index,]
test_data <- iris[-index,]
#transform teh two data sets into xgb.Matrix
xgb.train = xgb.DMatrix(data = as.matrix(train_data),label = as.matrix(train_data$Species))
(caret)
(caret)
(caret)
(caret)
library(xgboost)
library(caret)
data(iris)
index <- createDataPartition(iris$Species, p =0.7, list =F)
train_data <- iris[index,]
test_data <- iris[-index,]
#transform teh two data sets into xgb.Matrix
xgb.train = xgb.DMatrix(data = as.matrix(train_data),label = as.matrix(train_data$Species))
View(iris)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
iris
xgb.test = xgb.DMatrix(data = as.matrix(test_data),label = as.matrix(test_data$Species))
params = list(
booster "gbtree",
eta = 0.001,
max_depth = 5,
gamma = 3,
subsample = 0.7,
colsample_bytree = 1,
objective = "multi:softprob",
eval_metric = "mlogloss",
num_class = num_class
)
params = list(
booster ="gbtree",
eta = 0.001,
max_depth = 5,
gamma = 3,
subsample = 0.7,
colsample_bytree = 1,
objective = "multi:softprob",
eval_metric = "mlogloss",
num_class = num_class
)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
params = list(
booster ="gbtree",
eta = 0.001,
max_depth = 5,
gamma = 3,
subsample = 0.7,
colsample_bytree = 1,
objective = "multi:softprob",
eval_metric = "mlogloss",
num_class = num_class
)
xgb.fit = xgb.train(
params = params,
data = xgb.train,
nrounds = 10000,
nthreads -1,
early_stopping_rounds = 10,
watchlist = list(val1 = xgb.train,val2 = xgb.test),
verbose = 0
)
xgb.fit
source('~/.active-rstudio-document', echo=TRUE)
levels(iris$Species)
iris$Species
max
max(iris$Species)
source('~/.active-rstudio-document', echo=TRUE)
install.packages("xgboost")
install.packages("xgboost")
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
params = list(
booster ="gbtree",
eta = 0.001,
max_depth = 5,
gamma = 3,
subsample = 0.7,
colsample_bytree = 1,
objective = "multi:softprob",
eval_metric = "mlogloss",
num_class = num_class
)
xgb.fit = xgb.train(
params = params,
data = xgb.train,
nrounds = 10000,
nthreads = -1,
early_stopping_rounds = 10,
watchlist = list(val1 = xgb.train,val2 = xgb.test),
verbose = 0
)
xgb.fit
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
library(xgboost)
library(caret)
library(magrittr)
library(dplyr)
library(Matrix)
data(iris)
#IT should be a must to add as.numeric to the problem.
iris$Species <-  as.numeric(factor(iris$Species))
index <- createDataPartition(iris$Species, p =0.7, list =F)
train_data <- iris[index,]
test_data <- iris[-index,]
#transform teh two data sets into xgb.Matrix
xgb.train = xgb.DMatrix(data = as.matrix(train_data),label = as.matrix(train_data$Species))
xgb.test = xgb.DMatrix(data = as.matrix(test_data),label = as.matrix(test_data$Species))
#get the number of classes
num_class = max(iris$Species)-1
params = list(
booster ="gbtree",
eta = 0.001,
max_depth = 5,
gamma = 3,
subsample = 0.7,
colsample_bytree = 1,
objective = "multi:softprob",
eval_metric = "mlogloss",
num_class = num_class
)
xgb.fit = xgb.train(
params = params,
data = xgb.train,
nrounds = 10000,
nthreads = -1,
early_stopping_rounds = 10,
watchlist = list(val1 = xgb.train,val2 = xgb.test),
verbose = 0
)
xgb.fit
#get the number of classes
num_class = 2
params = list(
booster ="gbtree",
eta = 0.001,
max_depth = 5,
gamma = 3,
subsample = 0.7,
colsample_bytree = 1,
objective = "multi:softprob",
eval_metric = "mlogloss",
num_class = num_class
)
xgb.fit = xgb.train(
params = params,
data = xgb.train,
nrounds = 10000,
nthreads = -1,
early_stopping_rounds = 10,
watchlist = list(val1 = xgb.train,val2 = xgb.test),
verbose = 0
)
xgb.fit
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
level <- iris$Species
install.packages('dplyur')
install.packages('dplyr')
install.packages("dplyr")
install.packages("dplyr")
library()
library(dply)
library(dplyr)
library('dplyr')
install.packages(readr)
install.packages('readr')
install.packages('catboost')
install.packages('lattice')
install.packages("lattice")
library(catboost)
library(catboost)
install.packages
install.packages('catboost',lib = 'C:\\Users\\horat\\AppData\\Local\\Temp\\RtmpuOj8ZO\\downloaded_packages')
devtools::install_url('https://github.com/catboost/catboost/releases/download/v0.6.1.1/catboost-R-Windows-0.6.1.1.tgz',
args = c("--no-multiarch"))
library(catboost)
catboos
install.packages('devtools')
devtools::install_url('https://github.com/catboost/catboost/releases/download/v0.6.1.1/catboost-R-Windows-0.6.1.1.tgz',
args = c("--no-multiarch"))
install.packages("C:\\Users\\horat\\AppData\\Local\\Temp\\RtmpuOj8ZO\\downloaded_packages\\catboost-0.22.zip", repos = NULL, type = "source", INSTALL_opts = c("--no-multiarch", "--no-test-load"))
install.packages("C:\\Users\\horat\\AppData\\Local\\Temp\\RtmpuOj8ZO\\downloaded_packages\\catboost-0.22.zip", repos = NULL, type = "source")
install.packages("C:\\Users\\horat\\AppData\\Local\\Temp\\RtmpuOj8ZO\\downloaded_packages\\catboost-0.22.zip", repos = NULL)
install.packages("D:\\Program Files\\catboost-0.22.zip", repos = NULL)
install.packages("D:/Program Files/catboost-0.22.zip", repos = NULL, type = "win.binary")
library(lightgbm)
install.packages('lightgbm')
install.packages('data.tools')
install.packages('magrittr')
install.packages("magrittr")
install.packages("magrittr")
install.packages("R6")
install.packages("R6")
install.packages("R6")
install.packages("jsonlite")
devtools::install_url('https://github.com/catboost/catboost/releases/download/v0.7.2/catboost-R-Windows-0.7.2.tgz', args = c("--no-multiarch"))
devtools::install_url('https://github.com/catboost/catboost/releases/download/v0.22/catboost-R-windows-0.22.tgz', args = c("--no-multiarch"))
library(devtools)
install('devtools')
install.packages('devtools')
devtools::install_url('https://github.com/catboost/catboost/releases/download/v0.22/catboost-R-windows-0.22.tgz', args = c("--no-multiarch"))
library(devtools)
install.packages(devtools,dependencies = T)
install.packages('devtools',dependencies = T)
devtools::install_url('https://github.com/catboost/catboost/releases/download/v0.22/catboost-R-windows-0.22.tgz', args = c("--no-multiarch"))
libraray(lightgbm)
libraray('lightgbm')
library('lightgbm')
library(lightgbm)
devtools::install_url('https://github.com/catboost/catboost/releases/download/v0.22/catboost-R-windows-0.22.tgz', args = c("--no-multiarch"))
devtools::install_url('https://github.com/catboost/catboost/releases/download/v0.22/catboost-R-Windows-0.22.tgz', INSTALL_opts = c("--no-multiarch"))
install.packages('data.table')
install.packages('data.table')
install.packages("data.table")
install.packages("data.table")
install.packages("data.table")
library ('data.table')
library(devtools)
options(devtools.install.args = "--no-multiarch")
install_git("https://github.com/Microsoft/LightGBM", subdir = "R-package")
install.packages("C:/Users/horat/Desktop/LightGBM/lightgbm_2.3.2.tar.gz", repos = NULL, type = "source")
library('LightGBM')
library('lightgbm')
source('C:/Users/horat/Desktop/CSIROIntership/soilCode/soil.r', echo=TRUE)
memory.limit(150000000)
#add data limit
library(caret)
library(psych)
library (rattle)
#load the soil data
soil <- read.csv(file = "hr_lr_labm.csv")
labmCode <- soil$labm_code
labrValue <- soil$labr_value
memory.limit(150000000)
#add data limit
library(caret)
library(psych)
library (rattle)
#load the soil data
soil <- read.csv(file = "hr_lr_labm.csv")
labmCode <- soil$labm_code
source('C:/Users/horat/Desktop/CSIROIntership/soilCode/soil.r', echo=TRUE)
setwd("C:/Users/horat/Desktop/CSIROIntership/soilCode")
source('C:/Users/horat/Desktop/CSIROIntership/soilCode/soil.r', echo=TRUE)
source('C:/Users/horat/Desktop/CSIROIntership/soilCode/soil.r', echo=TRUE)
source('C:/Users/horat/Desktop/CSIROIntership/soilCode/soil.r', echo=TRUE)
View(classifier)
View(classifier)
source('C:/Users/horat/Desktop/CSIROIntership/soilCode/soil.r', echo=TRUE)
View(classifier)
y_Svm_pred <- predict(svmClassifier,newdata = test_set[,c("labm_code","labr_value")])
source('C:/Users/horat/Desktop/CSIROIntership/soilCode/soil.r', echo=TRUE)
y_Svm_pred
y_Svm_train_pred
svm_model <- svm(h_soil_water_stat ~ ., data=validsoilSample)
source('C:/Users/horat/Desktop/CSIROIntership/soilCode/soil.r', echo=TRUE)
split = sample.split(validsoilSample$h_soil_water_stat,SplitRatio = 0.75)
training_set = subset(validsoilSample, split == TRUE)
test_set = subset(validsoilSample, split ==FALSE)
x <- subset(validsoilSample, select=-h_soil_water_stat)
y <- h_soil_water_stat
View(x)
View(x)
x <- subset(validsoilSample, select=-h_soil_water_stat)
y <- validsoilSample$h_soil_water_stat
svm_model <- svm(h_soil_water_stat ~ ., data=validsoilSample)
summary(svm_model)
svm_tune <- tune(svm, train.x=x, train.y=y,
kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
print(svm_tune)
print(svm_tune)
svm_tune <- tune(svm, train.x=x, train.y=y,
kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
>
source('C:/Users/horat/Desktop/CSIROIntership/soilCode/soil.r', echo=TRUE)
